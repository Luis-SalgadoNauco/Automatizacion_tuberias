# Automatizaci√≥n de Tuber√≠as ‚Äì Apache Airflow

Repositorio de trabajo semanal para el aprendizaje pr√°ctico de **Apache Airflow**, enfocado en la creaci√≥n, ejecuci√≥n y documentaci√≥n de DAGs para la automatizaci√≥n de procesos de datos.

---

## Descripci√≥n general de la semana

Durante esta semana se trabajar√° con Apache Airflow desde un entorno Ubuntu, partiendo desde una instalaci√≥n limpia hasta la construcci√≥n de workflows m√°s completos.  
El enfoque ser√° **pr√°ctico**, priorizando:

- Buenas pr√°cticas de estructura de proyectos
- Versionamiento correcto con Git y GitHub
- Generaci√≥n de evidencias de ejecuci√≥n
- Comprensi√≥n conceptual de DAGs y orquestaci√≥n

Este repositorio se utiliza como **carpeta base para toda la semana**, evitando problemas de rutas y facilitando la trazabilidad del trabajo realizado.

---

## Objetivos de la semana

- Comprender qu√© es Apache Airflow y para qu√© se utiliza
- Crear DAGs funcionales desde cero
- Ejecutar DAGs manualmente y mediante scheduler
- Analizar logs y resultados de ejecuci√≥n
- Documentar correctamente cada avance
- Mantener un repositorio ordenado y versionado

---

## D√≠a 1 ‚Äì Primer DAG funcional en Apache Airflow

### Objetivo del d√≠a

- Instalar Apache Airflow en Ubuntu
- Configurar el entorno virtual y `AIRFLOW_HOME`
- Crear y ejecutar un DAG b√°sico
- Verificar la correcta ejecuci√≥n desde la UI y la consola
- Generar evidencia del trabajo realizado

---

### Trabajo realizado

Durante el D√≠a 1 se realizaron las siguientes actividades:

- Creaci√≥n de un entorno virtual en Python
- Instalaci√≥n de Apache Airflow
- Inicializaci√≥n y migraci√≥n de la base de datos
- Configuraci√≥n correcta del directorio `AIRFLOW_HOME`
- Creaci√≥n del primer DAG llamado **`saludo_diario`**
- Ejecuci√≥n manual del DAG desde:
  - Interfaz Web (Graph View)
  - Consola mediante `airflow dags trigger`
  - Consola mediante `airflow dags test`
- Generaci√≥n de archivos de evidencia con la salida de ejecuci√≥n

---

### DAG creado

**Nombre:** `saludo_diario`

**Tareas incluidas:**

1. `tarea_bash`  
   Imprime la fecha y hora de ejecuci√≥n mediante un comando Bash.

2. `tarea_python`  
   Ejecuta una funci√≥n Python que imprime un mensaje de saludo.

3. `tarea_esperar`  
   Simula un proceso de espera usando `sleep`.

Las tareas se ejecutan de forma **secuencial**, respetando la l√≥gica definida en el DAG.

---

### Evidencia de ejecuci√≥n ‚Äì D√≠a 1

Las evidencias del D√≠a 1 se encuentran en la carpeta `evidencia/` e incluyen:

- `ejecucion_saludo_diario.txt`  
  Salida de la ejecuci√≥n manual del DAG.

- `detalle_ejecucion_dia1.png`  
  Captura detallada de la ejecuci√≥n de tareas.

- `grafico_dia1.png`  
  Visualizaci√≥n del DAG en **Graph View** desde la Web UI.

---

### Verificaci√≥n ‚Äì D√≠a 1

**¬øQu√© es un DAG en Airflow?**  
Un DAG (Directed Acyclic Graph) es un grafo dirigido sin ciclos que define la estructura de un workflow, especificando tareas y sus dependencias.

**¬øPara qu√© sirve definir dependencias entre tareas?**  
Permite controlar el orden de ejecuci√≥n, asegurar que ciertas tareas solo se ejecuten cuando otras hayan finalizado correctamente y evitar ejecuciones inconsistentes.

**¬øCu√°l es la diferencia entre ejecutar un DAG con `trigger` y con `test`?**  
- `trigger` ejecuta el DAG completo usando el scheduler.
- `test` ejecuta el DAG de forma local y secuencial, √∫til para pruebas y depuraci√≥n.

**¬øPor qu√© es importante generar evidencia de ejecuci√≥n?**  
Porque permite validar que el DAG funciona correctamente, facilita la auditor√≠a del proceso y deja trazabilidad del trabajo realizado.

---

## D√≠a 2 ‚Äì DAG con dependencias complejas

### Objetivo del d√≠a

- Construir un DAG con m√∫ltiples ramas y dependencias
- Ejecutar tareas en paralelo
- Comprender el flujo visual de un DAG complejo
- Ejecutar y validar el pipeline desde la consola
- Generar evidencia de ejecuci√≥n

---

### Trabajo realizado

Durante el D√≠a 2 se realizaron las siguientes actividades:

- Creaci√≥n del DAG **`pipeline_ventas_complejo`**
- Definici√≥n de tareas de:
  - Preparaci√≥n de entorno
  - Extracci√≥n de datos
  - Validaci√≥n
  - Transformaci√≥n
  - Uni√≥n de datos (join)
  - Carga final
  - Reporte de ejecuci√≥n
- Implementaci√≥n de dependencias complejas con ejecuci√≥n paralela
- Ejecuci√≥n del DAG mediante:
  - `airflow dags test`
  - `airflow dags trigger`
- Verificaci√≥n del flujo en la Web UI (Graph View)

---

### Flujo del DAG

preparar_entorno ‚Üí [extraer_api, extraer_db]
extraer_api ‚Üí validar_api ‚Üí transformar_ventas ‚Üò
extraer_db ‚Üí validar_db ‚Üí transformar_productos ‚Üò ‚Üí join_datos ‚Üí cargar_dw ‚Üí enviar_reporte

---

### Evidencia de ejecuci√≥n ‚Äì D√≠a 2

Las evidencias del D√≠a 2 se encuentran en la carpeta `evidencia/`:

- `ejecucion_pipeline_ventas_complejo.txt`  
  Salida completa de la ejecuci√≥n del pipeline.

- `detalle_ejecucion_dia2.png`  
  Captura del detalle de ejecuci√≥n de las tareas.

- `grafico_dia2.png`  
  Visualizaci√≥n del DAG con dependencias complejas en **Graph View**.

---

### Verificaci√≥n ‚Äì D√≠a 2

**¬øCu√°ndo usar PythonOperator en lugar de BashOperator?**  
Se utiliza PythonOperator cuando la l√≥gica de la tarea requiere procesamiento, validaciones o transformaciones en Python.  
BashOperator es ideal para comandos del sistema, scripts o tareas simples de infraestructura.

**¬øQu√© ventajas tiene definir dependencias expl√≠citas?**  
- Permite paralelismo controlado
- Mejora la claridad del flujo
- Facilita mantenimiento y escalabilidad
- Reduce errores por ejecuci√≥n fuera de orden
---

## üìò D√≠a 3 ‚Äì Operadores, Sensores y Operadores Personalizados

### Objetivo del d√≠a

- Conocer los operadores m√°s comunes de Apache Airflow
- Comprender el uso de sensores para esperar condiciones externas
- Crear y utilizar un operador personalizado
- Construir un DAG que combine sensores, operadores est√°ndar y personalizados
- Verificar la ejecuci√≥n correcta desde la UI y la consola
- Generar evidencia gr√°fica de la ejecuci√≥n

---

### Trabajo realizado

Durante el D√≠a 3 se realizaron las siguientes actividades:

- Revisi√≥n de operadores comunes:
  - `BashOperator`
  - `PythonOperator`
- Introducci√≥n y uso de sensores:
  - `FileSensor` para esperar la llegada de archivos
- Creaci√≥n de un operador personalizado para validaci√≥n de datos
- Construcci√≥n del DAG **`pipeline_con_sensores`**
- Ejecuci√≥n manual del DAG desde la consola
- Monitoreo del flujo de tareas desde la Web UI
- An√°lisis de estados y resoluci√≥n de errores durante la ejecuci√≥n
- Generaci√≥n de evidencia visual del DAG ejecutado correctamente

---

### DAG creado

**Nombre:** `pipeline_con_sensores`

**Descripci√≥n:**  
Pipeline que espera la llegada de un archivo de ventas, valida su calidad, procesa la informaci√≥n, genera un reporte y finalmente limpia los archivos temporales.

---

### Tareas incluidas

1. **`esperar_archivo_datos`** (`FileSensor`)  
   Espera la existencia del archivo `/tmp/datos_ventas.csv` antes de continuar el flujo.

2. **`validar_datos_ventas`** (Operador personalizado)  
   Lee el archivo CSV y valida la calidad de los datos seg√∫n un umbral definido.

3. **`procesar_datos_ventas`** (`PythonOperator`)  
   Simula el procesamiento de los datos de ventas.

4. **`generar_reporte`** (`PythonOperator`)  
   Simula la generaci√≥n de un reporte ejecutivo.

5. **`limpiar_archivos`** (`BashOperator`)  
   Elimina el archivo temporal utilizado en el proceso.

El flujo del DAG es **secuencial**:

## üìò D√≠a 3 ‚Äì Operadores, Sensores y Operadores Personalizados

### Objetivo del d√≠a

- Conocer los operadores m√°s comunes de Apache Airflow
- Comprender el uso de sensores para esperar condiciones externas
- Crear y utilizar un operador personalizado
- Construir un DAG que combine sensores, operadores est√°ndar y personalizados
- Verificar la ejecuci√≥n correcta desde la UI y la consola
- Generar evidencia gr√°fica de la ejecuci√≥n

---

### Trabajo realizado

Durante el D√≠a 3 se realizaron las siguientes actividades:

- Revisi√≥n de operadores comunes:
  - `BashOperator`
  - `PythonOperator`
- Introducci√≥n y uso de sensores:
  - `FileSensor` para esperar la llegada de archivos
- Creaci√≥n de un operador personalizado para validaci√≥n de datos
- Construcci√≥n del DAG **`pipeline_con_sensores`**
- Ejecuci√≥n manual del DAG desde la consola
- Monitoreo del flujo de tareas desde la Web UI
- An√°lisis de estados y resoluci√≥n de errores durante la ejecuci√≥n
- Generaci√≥n de evidencia visual del DAG ejecutado correctamente

---

### DAG creado

**Nombre:** `pipeline_con_sensores`

**Descripci√≥n:**  
Pipeline que espera la llegada de un archivo de ventas, valida su calidad, procesa la informaci√≥n, genera un reporte y finalmente limpia los archivos temporales.

---

### Tareas incluidas

1. **`esperar_archivo_datos`** (`FileSensor`)  
   Espera la existencia del archivo `/tmp/datos_ventas.csv` antes de continuar el flujo.

2. **`validar_datos_ventas`** (Operador personalizado)  
   Lee el archivo CSV y valida la calidad de los datos seg√∫n un umbral definido.

3. **`procesar_datos_ventas`** (`PythonOperator`)  
   Simula el procesamiento de los datos de ventas.

4. **`generar_reporte`** (`PythonOperator`)  
   Simula la generaci√≥n de un reporte ejecutivo.

5. **`limpiar_archivos`** (`BashOperator`)  
   Elimina el archivo temporal utilizado en el proceso.

El flujo del DAG es **secuencial**:

esperar_archivo_datos ‚Üí validar_datos_ventas ‚Üí procesar_datos_ventas ‚Üí generar_reporte ‚Üí limpiar_archivos

### Evidencia de ejecuci√≥n

Las evidencias del D√≠a 3 se encuentran en la carpeta `evidencia/` e incluyen:

- `detalle_ejecucion_dia3.png` ‚Äì Detalle de ejecuci√≥n de tareas
- `grafico_dia3.png` ‚Äì Vista gr√°fica del DAG ejecutado correctamente

---

### Aprendizajes clave

- Los sensores permiten sincronizar los DAGs con eventos externos.
- Un DAG no debe ejecutar tareas si no se cumplen las condiciones previas.
- Los operadores personalizados mejoran la reutilizaci√≥n y limpieza del c√≥digo.
- Airflow gestiona estados de tareas de forma independiente al resultado del scheduler.
- La Web UI es clave para depurar y entender la ejecuci√≥n de pipelines.

---

### Verificaci√≥n ‚Äì D√≠a 3

**¬øEn qu√© situaciones usar√≠as un sensor en lugar de ejecutar tareas inmediatamente?**  
Se utiliza un sensor cuando una tarea depende de un evento externo, como la llegada de un archivo, la disponibilidad de un servicio o la finalizaci√≥n de otro proceso. Esto evita fallos prematuros y permite que el flujo se ejecute solo cuando las condiciones son correctas.

**¬øCu√°les son las ventajas de crear operadores personalizados?**  
Permiten encapsular l√≥gica reutilizable, mantener los DAGs m√°s ordenados, estandarizar procesos, facilitar el mantenimiento y escalar soluciones de orquestaci√≥n de forma m√°s profesional.
---

## D√≠a 4 ‚Äì Monitoreo, m√©tricas y alertas en Airflow

### Objetivo
Implementar un DAG con monitoreo completo, m√©tricas, validaciones, alertas y control de SLA utilizando Apache Airflow.

---

### Actividades realizadas

- Creaci√≥n del DAG `pipeline_monitorado`
- Configuraci√≥n de par√°metros de monitoreo:
  - Reintentos autom√°ticos
  - Timeout de ejecuci√≥n
  - Callbacks de √©xito y fallo
- Implementaci√≥n de m√©tricas:
  - Tiempo de procesamiento
  - Registros procesados
  - Tasa de √©xito
- Uso de XCom para compartir m√©tricas entre tareas
- Validaci√≥n de umbrales de calidad
- Notificaci√≥n de √©xito mediante `EmailOperator`
- Verificaci√≥n de SLA al final del pipeline

---

### Ejecuci√≥n y monitoreo

- Las tareas `procesar_datos` y `validar_metricas` se ejecutaron correctamente.
- La tarea `notificar_exito` intent√≥ enviar un correo electr√≥nico.
- Debido a que el entorno local no tiene SMTP configurado, el env√≠o de correo no se complet√≥ autom√°ticamente.
- La tarea fue marcada manualmente como exitosa para continuar el flujo.
- El DAG finaliz√≥ exitosamente y permiti√≥ validar el monitoreo completo.

---

### Evidencias generadas

- `detalle_ejecucion_dia4.png`  
  Vista detallada de la ejecuci√≥n del DAG.

- `grafico_intento_aviso_dia4.png`  
  Evidencia del intento de notificaci√≥n por correo electr√≥nico.

- `grafico_completado_dia4.png`  
  Ejecuci√≥n final del DAG completado correctamente.

---

### Pregunta de verificaci√≥n

**¬øQu√© m√©tricas son m√°s importantes para monitorear en una tuber√≠a de datos y c√≥mo elegir el tipo de alerta?**

Las m√©tricas m√°s importantes son el estado de las tareas, tiempo de ejecuci√≥n, volumen de datos procesados, tasa de √©xito y cumplimiento de SLA.  
Las alertas por correo se usan para notificaciones formales, Slack para alertas operativas en tiempo real y SMS para incidentes cr√≠ticos.

---

## D√≠as restantes (planificaci√≥n)

- D√≠a 5

---

## Estructura del proyecto

```text
airflow_curso/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ mi_primer_dag.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_ventas_complejo.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_con_sensores.py
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_monitorado.py
‚îú‚îÄ‚îÄ evidencia/
‚îÇ   ‚îú‚îÄ‚îÄ ejecucion_saludo_diario.txt
‚îÇ   ‚îú‚îÄ‚îÄ detalle_ejecucion_dia1.png
‚îÇ   ‚îú‚îÄ‚îÄ grafico_dia1.png
‚îÇ   ‚îú‚îÄ‚îÄ ejecucion_pipeline_ventas_complejo.txt
‚îÇ   ‚îú‚îÄ‚îÄ detalle_ejecucion_dia2.png
‚îÇ   ‚îú‚îÄ‚îÄ grafico_dia2.png
‚îÇ   ‚îú‚îÄ‚îÄ detalle_ejecucion_dia3.png
‚îÇ   ‚îú‚îÄ‚îÄ grafico_dia3.png
‚îÇ   ‚îú‚îÄ‚îÄ detalle_ejecucion_dia4.png
‚îÇ   ‚îú‚îÄ‚îÄ grafico_intento_aviso_dia4.png
‚îÇ   ‚îî‚îÄ‚îÄ grafico_completado_dia4.png
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```
